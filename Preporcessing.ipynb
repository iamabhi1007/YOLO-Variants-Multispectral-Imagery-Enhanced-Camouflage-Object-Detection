{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##PIPELINE Idea 1 histogram and thresholding cobinations"
      ],
      "metadata": {
        "id": "nv1hI320Zmml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Count"
      ],
      "metadata": {
        "id": "wnX5xtpOWtQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Get the path to the folder\n",
        "folder_path = \"/content/drive/MyDrive/Dataset_2\"\n",
        "\n",
        "# Count the number of files in the folder\n",
        "num_files = len(os.listdir(folder_path))\n",
        "\n",
        "# Print the number of files\n",
        "print(f\"Number of files in the folder: {num_files}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC9n0k6MRaVG",
        "outputId": "d10f42e2-a05b-4954-93ca-d4e39a3f02bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in the folder: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Renyi's Entropy Thresholding"
      ],
      "metadata": {
        "id": "6RmuvVJVaDsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def renyi_entropy(image, alpha):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate histogram\n",
        "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
        "\n",
        "    # Normalize histogram\n",
        "    hist_norm = hist.ravel() / hist.sum()\n",
        "\n",
        "    # Compute cumulative distribution function (CDF)\n",
        "    cdf = hist_norm.cumsum()\n",
        "\n",
        "    # Compute Renyi's entropy\n",
        "    ren_entropy = (1 / (1 - alpha)) * np.log2(np.sum(hist_norm ** alpha))\n",
        "\n",
        "    # Find threshold with maximum Renyi's entropy\n",
        "    threshold = np.argmax(ren_entropy)\n",
        "\n",
        "    # Apply thresholding\n",
        "    _, thresholded_image = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return thresholded_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Renyi entropy parameter\n",
        "alpha = 0.5  # Adjust alpha as needed\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Apply Renyi's entropy thresholding\n",
        "        thresholded_image = renyi_entropy(image, alpha)\n",
        "\n",
        "        # Save thresholded image\n",
        "        process_name = \"renyi_entropy_thresholding\"\n",
        "        output_filename = os.path.splitext(filename)[0] + \"_\" + process_name + \".png\"\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "        cv2.imwrite(output_path, thresholded_image)\n",
        "\n",
        "print(\"Renyi's entropy thresholding complete. Thresholded images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KgCAT3baEIl",
        "outputId": "35736581-803a-40e8-f7c2-3d127e653f26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Renyi's entropy thresholding complete. Thresholded images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kapur's Entropy Thresholding"
      ],
      "metadata": {
        "id": "EV2Ji1a7Z18B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def kapur_entropy_thresholding(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate histogram\n",
        "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
        "\n",
        "    # Normalize histogram\n",
        "    hist_norm = hist.ravel() / hist.sum()\n",
        "\n",
        "    # Compute cumulative distribution function (CDF)\n",
        "    cdf = hist_norm.cumsum()\n",
        "\n",
        "    # Compute entropy for all possible thresholds\n",
        "    entropy = -np.sum(hist_norm * np.log2(np.maximum(hist_norm, 1e-10)) for hist_norm in np.array_split(hist_norm, range(1, 256)))\n",
        "\n",
        "    # Find threshold with maximum entropy\n",
        "    threshold = np.argmax(entropy)\n",
        "\n",
        "    # Apply thresholding\n",
        "    _, thresholded_image = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return thresholded_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Apply Kapur's entropy thresholding\n",
        "        thresholded_image = kapur_entropy_thresholding(image)\n",
        "\n",
        "        # Save thresholded image\n",
        "        process_name = \"kapur_entropy_thresholding\"\n",
        "        output_filename = os.path.splitext(filename)[0] + \"_\" + process_name + \".png\"\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "        cv2.imwrite(output_path, thresholded_image)\n",
        "\n",
        "print(\"Kapur's entropy thresholding complete. Thresholded images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3HQLqM9Z20b",
        "outputId": "f69df73e-e870-4c29-92d8-8e80d46a299a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kapur's entropy thresholding complete. Thresholded images saved in the output folder.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-eb385a8e2a5f>:19: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  entropy = -np.sum(hist_norm * np.log2(np.maximum(hist_norm, 1e-10)) for hist_norm in np.array_split(hist_norm, range(1, 256)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Triangle Thresholding"
      ],
      "metadata": {
        "id": "UOQGzuuDYkSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def triangle_thresholding(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Calculate histogram\n",
        "    hist = cv2.calcHist([gray], [0], None, [50], [0,200])\n",
        "\n",
        "    # Calculate triangle threshold\n",
        "    max_val = np.max(hist)\n",
        "    max_idx = np.argmax(hist)\n",
        "\n",
        "    # Find the maximum index of the difference between cumulative sums of histogram bins\n",
        "    left_sum = np.cumsum(hist[:max_idx+1])\n",
        "    right_sum = np.cumsum(hist[max_idx:])\n",
        "    diffs = np.abs(left_sum[:,np.newaxis] - right_sum[::-1])\n",
        "    threshold = np.argmax(diffs)\n",
        "\n",
        "    # Apply thresholding\n",
        "    _, thresholded_image = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    return thresholded_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Apply triangle thresholding\n",
        "        thresholded_image = triangle_thresholding(image)\n",
        "\n",
        "        # Save thresholded image\n",
        "        process_name = \"triangle_thresholding\"\n",
        "        output_filename = os.path.splitext(filename)[0] + \"_\" + process_name + \".png\"\n",
        "        output_path = os.path.join(output_folder, output_filename)\n",
        "        cv2.imwrite(output_path, thresholded_image)\n",
        "\n",
        "print(\"Triangle thresholding complete. Thresholded images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPYLGcOlYkJa",
        "outputId": "a459f95b-935d-41b5-ac68-d5cda55e2d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triangle thresholding complete. Thresholded images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Adaptive thr"
      ],
      "metadata": {
        "id": "kR-JjNGFYUo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def adaptive_thresholding(image):\n",
        "    # Apply adaptive thresholding\n",
        "    thresholded_image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
        "    return thresholded_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply adaptive thresholding\n",
        "        thresholded_image = adaptive_thresholding(image)\n",
        "\n",
        "        # Save thresholded image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, thresholded_image)\n",
        "\n",
        "print(\"Adaptive thresholding complete. Thresholded images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjMuXOeeYWbo",
        "outputId": "5994a849-b0a4-4889-d80a-70cd491f8571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaptive thresholding complete. Thresholded images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Otsu Thr."
      ],
      "metadata": {
        "id": "scz6f1gxX6y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def otsu_thresholding(image):\n",
        "    # Apply Otsu's thresholding\n",
        "    _, thresholded_image = cv2.threshold(image, 50, 200, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    return thresholded_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply Otsu's thresholding\n",
        "        thresholded_image = otsu_thresholding(image)\n",
        "\n",
        "        # Save thresholded image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, thresholded_image)\n",
        "\n",
        "print(\"Otsu's thresholding complete. Thresholded images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuoUAiUAX83u",
        "outputId": "b6866b41-f018-407e-a528-4bb48f90d3ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Otsu's thresholding complete. Thresholded images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Global Thresholding"
      ],
      "metadata": {
        "id": "661YT9ToXJBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def global_thresholding(image):\n",
        "    # Apply global thresholding with a higher threshold value\n",
        "    _, thresholded_image = cv2.threshold(image, 50, 200, cv2.THRESH_BINARY)\n",
        "    return thresholded_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Apply global thresholding\n",
        "        thresholded_image = global_thresholding(image)\n",
        "\n",
        "        # Save thresholded image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, thresholded_image)\n",
        "\n",
        "print(\"Global thresholding complete. Thresholded images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQPsNoNRXLQU",
        "outputId": "f83ccbb6-c75c-4e25-e153-87045f5b669b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global thresholding complete. Thresholded images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Erosion"
      ],
      "metadata": {
        "id": "K2qZhsdmVosU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def perform_erosion(image, kernel_size=(3, 3)):\n",
        "    # Define the kernel for erosion\n",
        "    kernel = np.ones(kernel_size, np.uint8)\n",
        "\n",
        "    # Perform erosion\n",
        "    eroded_image = cv2.erode(image, kernel, iterations=1)\n",
        "\n",
        "    return eroded_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Perform erosion\n",
        "        eroded_image = perform_erosion(image)\n",
        "\n",
        "        # Save eroded image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, eroded_image)\n",
        "\n",
        "print(\"Erosion complete. Eroded images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFkYF47VVqnT",
        "outputId": "dcfa6514-84e6-4af2-fc04-9235c7526cd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erosion complete. Eroded images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dilation"
      ],
      "metadata": {
        "id": "EC9Vm5LkV19i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def perform_dilation(image, kernel_size=(3, 3)):\n",
        "    # Define the kernel for dilation\n",
        "    kernel = np.ones(kernel_size, np.uint8)\n",
        "\n",
        "    # Perform dilation\n",
        "    dilated_image = cv2.dilate(image, kernel, iterations=1)\n",
        "\n",
        "    return dilated_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/path/to/input/folder\"\n",
        "output_folder = \"/path/to/output/folder\"\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def perform_dilation(image, kernel_size=(3, 3)):\n",
        "    # Define the kernel for dilation\n",
        "    kernel = np.ones(kernel_size, np.uint8)\n",
        "\n",
        "    # Perform dilation\n",
        "    dilated_image = cv2.dilate(image, kernel, iterations=1)\n",
        "\n",
        "    return dilated_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Perform dilation\n",
        "        dilated_image = perform_dilation(image)\n",
        "\n",
        "        # Save dilated image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, dilated_image)\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists('output'):\n",
        "    os.makedirs('output')\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Perform dilation\n",
        "        dilated_image = perform_dilation(image)\n",
        "\n",
        "        # Save dilated image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, dilated_image)\n",
        "\n",
        "print(\"Dilation complete. Dilated images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg6sLSLgV3iP",
        "outputId": "3f393878-6559-4749-b881-ac77d176509a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dilation complete. Dilated images saved in the output folder.\n",
            "Dilation complete. Dilated images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Open"
      ],
      "metadata": {
        "id": "e6BCL3MJWM2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def perform_opening(image, kernel_size=(3, 3)):\n",
        "    # Define the kernel for opening\n",
        "    kernel = np.ones(kernel_size, np.uint8)\n",
        "\n",
        "    # Perform opening\n",
        "    opened_image = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    return opened_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Perform opening\n",
        "        opened_image = perform_opening(image)\n",
        "\n",
        "        # Save opened image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, opened_image)\n",
        "\n",
        "print(\"Opening operation complete. Opened images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy0fHa8vWPMm",
        "outputId": "e6e1b4bf-c6ed-4395-ad04-b1f27deffa4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Opening operation complete. Opened images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Close"
      ],
      "metadata": {
        "id": "RPbWR_khWOHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def perform_closing(image, kernel_size=(3, 3)):\n",
        "    # Define the kernel for closing\n",
        "    kernel = np.ones(kernel_size, np.uint8)\n",
        "\n",
        "    # Perform closing\n",
        "    closed_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    return closed_image\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Perform closing\n",
        "        closed_image = perform_closing(image)\n",
        "\n",
        "        # Save closed image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, closed_image)\n",
        "\n",
        "print(\"Closing operation complete. Closed images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUwTU7xEWPld",
        "outputId": "ee9c971c-16de-419e-c2c8-b87b8d17e9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing operation complete. Closed images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLAHE"
      ],
      "metadata": {
        "id": "woxa3fVXU0X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def apply_CLAHE(image, clip_limit=2.0, grid_size=(8, 8)):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create CLAHE object\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)\n",
        "\n",
        "    # Apply CLAHE to the grayscale image\n",
        "    clahe_image = clahe.apply(gray)\n",
        "\n",
        "    # Convert back to BGR\n",
        "    clahe_image_bgr = cv2.cvtColor(clahe_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    return clahe_image_bgr\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/path/to/input/folder\"\n",
        "output_folder = \"/path/to/output/folder\"\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def apply_CLAHE(image, clip_limit=2.0, grid_size=(8, 8)):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Create CLAHE object\n",
        "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=grid_size)\n",
        "\n",
        "    # Apply CLAHE to the grayscale image\n",
        "    clahe_image = clahe.apply(gray)\n",
        "\n",
        "    # Convert back to BGR\n",
        "    clahe_image_bgr = cv2.cvtColor(clahe_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    return clahe_image_bgr\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Apply CLAHE\n",
        "        clahe_image = apply_CLAHE(image)\n",
        "\n",
        "        # Save processed image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, clahe_image)\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Apply CLAHE\n",
        "        clahe_image = apply_CLAHE(image)\n",
        "\n",
        "        # Save processed image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, clahe_image)\n",
        "\n",
        "print(\"CLAHE processing complete. Processed images saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIGNjMiBU1rh",
        "outputId": "ece0139f-2470-4dd0-db47-d8320184a3c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLAHE processing complete. Processed images saved in the output folder.\n",
            "CLAHE processing complete. Processed images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ORB"
      ],
      "metadata": {
        "id": "j0JNfJRGUTSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "def detect_and_compute_ORB(image):\n",
        "    # Convert image to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Initialize ORB detector\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    # Detect keypoints and compute descriptors\n",
        "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
        "\n",
        "    # Draw keypoints on the image\n",
        "    image_with_keypoints = cv2.drawKeypoints(image, keypoints, None, color=(0, 255, 0), flags=0)\n",
        "\n",
        "    return image_with_keypoints, keypoints, descriptors\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        # Detect and compute ORB features\n",
        "        image_with_keypoints, _, _ = detect_and_compute_ORB(image)\n",
        "\n",
        "        # Save image with keypoints\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        cv2.imwrite(output_path, image_with_keypoints)\n",
        "\n",
        "print(\"ORB feature detection complete. Images with keypoints saved in the output folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKz_Y8y2UUSv",
        "outputId": "b81d4ccf-9ac7-4114-d638-22922ca2ad22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORB feature detection complete. Images with keypoints saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Segmentation"
      ],
      "metadata": {
        "id": "KtvoB1A4TaBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from skimage import io, color, segmentation\n",
        "from skimage.filters import sobel\n",
        "from skimage.color import rgb2gray\n",
        "from skimage.segmentation import felzenszwalb\n",
        "\n",
        "# Function to perform segmentation on an image\n",
        "def segment_image(image):\n",
        "    # Convert image to RGB if it is grayscale\n",
        "    if image.ndim == 2:\n",
        "        image = color.gray2rgb(image)\n",
        "\n",
        "    # Perform edge-based segmentation\n",
        "    gray_image = rgb2gray(image)\n",
        "    edges = sobel(gray_image)\n",
        "    segments = felzenszwalb(edges, scale=100, sigma=0.5, min_size=50)\n",
        "\n",
        "    return segments\n",
        "\n",
        "# Input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/A_test\"\n",
        "output_folder = \"/content/drive/MyDrive/A_test_d\"\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Iterate through images in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "        # Read the image\n",
        "        image_path = os.path.join(input_folder, filename)\n",
        "        image = io.imread(image_path)\n",
        "\n",
        "        # Perform segmentation\n",
        "        segmented_image = segment_image(image)\n",
        "\n",
        "        # Save segmented image\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        io.imsave(output_path, segmented_image.astype('uint8'))\n",
        "\n",
        "print(\"Segmentation complete. Segmented images saved in the output folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXXyokKZTZwy",
        "outputId": "4692325e-d1e7-451d-abed-df42c6152575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation complete. Segmented images saved in the output folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fusion(working)**"
      ],
      "metadata": {
        "id": "hTVcLfe21VOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def resize_image(img, target_size=(400, 400)):\n",
        "    # Resize the image to the target size\n",
        "    return cv2.resize(img, target_size)\n",
        "\n",
        "def fuse_images(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all files in the input folder\n",
        "    files = sorted(os.listdir(input_folder))  # Sort files to ensure serial processing\n",
        "\n",
        "    # Initialize a variable to keep track of the current set of images\n",
        "    image_set_count = 0\n",
        "    image_set = []\n",
        "\n",
        "    for file in files:\n",
        "        if file.endswith(('.jpg', '.jpeg', '.png','.tif')):  # Check if the file is an image file\n",
        "            # Read the image\n",
        "            img_path = os.path.join(input_folder, file)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Resize the image to a common size\n",
        "            img = resize_image(img)\n",
        "\n",
        "            # Add the image to the current set\n",
        "            image_set.append(img)\n",
        "\n",
        "            # If the current set has 6 images, fuse them and save the result\n",
        "            if len(image_set) == 6:\n",
        "                # Fuse images in the set\n",
        "                fused_image = fuse_set_of_images(image_set)\n",
        "\n",
        "                # Save the fused image\n",
        "                output_path = os.path.join(output_folder, f\"fused_image_{image_set_count}.jpg\")\n",
        "                cv2.imwrite(output_path, fused_image)\n",
        "\n",
        "                print(f\"Fused image {image_set_count} saved successfully.\")\n",
        "\n",
        "                # Reset the image set for the next set of images\n",
        "                image_set_count += 1\n",
        "                image_set = []\n",
        "\n",
        "    # If there are any remaining images that haven't been processed, fuse them\n",
        "    if image_set:\n",
        "        fused_image = fuse_set_of_images(image_set)\n",
        "        output_path = os.path.join(output_folder, f\"fused_image_{image_set_count}.jpg\")\n",
        "        cv2.imwrite(output_path, fused_image)\n",
        "        print(f\"Fused image {image_set_count} saved successfully.\")\n",
        "\n",
        "def fuse_set_of_images(images):\n",
        "    # Use averaging to fuse images\n",
        "    fused_image = np.mean(images, axis=0).astype(np.uint8)\n",
        "    return fused_image\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"/content/drive/MyDrive/datasetPREPROCESS/DATA_FOR FUSION\"\n",
        "output_folder = \"/content/drive/MyDrive/output2(Fusion)\"\n",
        "fuse_images(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8g2r49m1U1y",
        "outputId": "bd9333a9-e635-4ce0-b920-6864f5a6662d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fused image 0 saved successfully.\n",
            "Fused image 1 saved successfully.\n",
            "Fused image 2 saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pan sharpening(not working)**"
      ],
      "metadata": {
        "id": "ccu3qxtm8QCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def pan_sharpen(fused_image_path, bands_folder, output_folder):\n",
        "    # Check if the fused image path exists\n",
        "    if not os.path.exists(fused_image_path):\n",
        "        print(f\"Error: Fused image file '{fused_image_path}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Check if the bands folder path exists\n",
        "    if not os.path.exists(bands_folder):\n",
        "        print(f\"Error: Bands folder '{bands_folder}' not found.\")\n",
        "        return\n",
        "\n",
        "    # Load the fused image\n",
        "    fused_image = cv2.imread(fused_image_path)\n",
        "\n",
        "    # Check if the fused image is loaded successfully\n",
        "    if fused_image is None:\n",
        "        print(\"Error: Failed to load the fused image.\")\n",
        "        return\n",
        "\n",
        "    # Load all six bands (excluding the panchromatic band)\n",
        "    bands = []\n",
        "    for i in range(1, 6):\n",
        "        band_path = os.path.join(bands_folder, f\"IMG_0000_{i}.tif\")\n",
        "        band_image = cv2.imread(band_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if band_image is None:\n",
        "            print(f\"Error: Failed to load band image '{band_path}'.\")\n",
        "            return\n",
        "        bands.append(band_image)\n",
        "\n",
        "    # Load the panchromatic band\n",
        "    panchromatic_band_path = os.path.join(bands_folder, \"IMG_0000_6.tif\")\n",
        "    panchromatic_band_image = cv2.imread(panchromatic_band_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if panchromatic_band_image is None:\n",
        "        print(f\"Error: Failed to load panchromatic band image '{panchromatic_band_path}'.\")\n",
        "        return\n",
        "\n",
        "    # Resize the panchromatic band to match the fused image\n",
        "    panchromatic_band_image = cv2.resize(panchromatic_band_image, (fused_image.shape[1], fused_image.shape[0]))\n",
        "\n",
        "    # Convert images to float32 for calculations\n",
        "    fused_image = fused_image.astype(np.float32)\n",
        "    panchromatic_band_image = panchromatic_band_image.astype(np.float32)\n",
        "\n",
        "    # Perform pan-sharpening using the Brovey Transform\n",
        "    pan_sharpened_image = np.zeros_like(fused_image)\n",
        "    for channel in range(3):\n",
        "        pan_sharpened_image[:, :, channel] = (fused_image[:, :, channel] / fused_image.max()) * panchromatic_band_image\n",
        "\n",
        "    # Convert back to uint8\n",
        "    pan_sharpened_image = np.clip(pan_sharpened_image, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Save the pan-sharpened image\n",
        "    output_path = os.path.join(output_folder, \"pan_sharpened_image.jpg\")\n",
        "    cv2.imwrite(output_path, pan_sharpened_image)\n",
        "\n",
        "    print(\"Pan-sharpening complete. Pan-sharpened image saved successfully.\")\n",
        "\n",
        "# Example usage\n",
        "fused_image_path = \"/content/drive/MyDrive/output2Fusion\"  # Path to the fused image\n",
        "bands_folder = \"/content/drive/MyDrive/datasetPREPROCESS/DATA_FOR FUSION\"  # Folder containing all six bands and the panchromatic band\n",
        "output_folder = \"/content/drive/MyDrive/output3(Pansharped)\"  # Output folder where the pan-sharpened image will be saved\n",
        "\n",
        "pan_sharpen(fused_image_path, bands_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DOkXr248Trt",
        "outputId": "e154eb6f-9c63-4275-e7fd-e52c30f4a9e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to load the fused image.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***False coluring(working)***"
      ],
      "metadata": {
        "id": "El4qcUckz-Dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def apply_colormap(img_gray, colormap=cv2.COLORMAP_JET):\n",
        "    # Apply colormap to the grayscale image\n",
        "    return cv2.applyColorMap(img_gray, colormap)\n",
        "\n",
        "def false_color(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all files in the input folder\n",
        "    files = os.listdir(input_folder)\n",
        "\n",
        "    for file in files:\n",
        "        if file.endswith(('.jpg', '.jpeg', '.png')):  # Check if the file is an image file\n",
        "            # Read the image\n",
        "            img_path = os.path.join(input_folder, file)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Convert image to grayscale\n",
        "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Apply false coloring using a colormap\n",
        "            false_colored_img = apply_colormap(img_gray)\n",
        "\n",
        "            # Save the false colored image\n",
        "            output_path = os.path.join(output_folder, file)\n",
        "            cv2.imwrite(output_path, false_colored_img)\n",
        "\n",
        "            print(f\"{file} processed successfully.\")\n",
        "\n",
        "\n",
        "# Example usage\n",
        "input_folder = \"/content/drive/MyDrive/datasetPREPROCESS\"\n",
        "output_folder = \"/content/drive/MyDrive/output1\"\n",
        "false_color(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ1ddL0lz9gv",
        "outputId": "8e53fa0e-6a02-403b-c9fe-005ab209d86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0013.jpg processed successfully.\n",
            "2442.jpg processed successfully.\n",
            "0366.jpg processed successfully.\n",
            "0144.jpg processed successfully.\n",
            "3849.jpg processed successfully.\n",
            "1794.jpg processed successfully.\n",
            "1539.jpg processed successfully.\n",
            "3813.jpg processed successfully.\n",
            "2831.jpg processed successfully.\n",
            "4010.jpg processed successfully.\n",
            "2288.jpg processed successfully.\n",
            "1707.jpg processed successfully.\n",
            "2159.jpg processed successfully.\n",
            "0562.jpg processed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Delete folder"
      ],
      "metadata": {
        "id": "iHPyZZDEaxSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Delete all files in a folder which i wioll give a path\n",
        "\n",
        "import os\n",
        "\n",
        "def delete_files_in_folder(folder_path):\n",
        "  for filename in os.listdir(folder_path):\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "    try:\n",
        "      if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "        os.unlink(file_path)\n",
        "      elif os.path.isdir(file_path):\n",
        "        delete_files_in_folder(file_path)\n",
        "        os.rmdir(file_path)\n",
        "    except Exception as e:\n",
        "      print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
        "\n",
        "# Example usage:\n",
        "folder_path = '/content/drive/MyDrive/Gabor'\n",
        "delete_files_in_folder(folder_path)\n"
      ],
      "metadata": {
        "id": "zHCgGu2rfweD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Kmeans"
      ],
      "metadata": {
        "id": "iHCk2L94hKuN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###No problem, stopped execution since it was taking too long to execute"
      ],
      "metadata": {
        "id": "DgLYyFrrhuXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def k_means_segmentation(input_folder, output_folder, num_clusters=3):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Convert the image to the RGB color space\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Reshape the image to a 2D array of pixels (rows x columns, 3 color channels)\n",
        "            pixels = image_rgb.reshape((-1, 3))\n",
        "\n",
        "            # Convert to float32 for k-means algorithm\n",
        "            pixels = np.float32(pixels)\n",
        "\n",
        "            # Define criteria and apply k-means algorithm\n",
        "            criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
        "            _, labels, centers = cv2.kmeans(pixels, num_clusters, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "            # Convert the centers back to uint8\n",
        "            centers = np.uint8(centers)\n",
        "\n",
        "            # Map each pixel to its corresponding center\n",
        "            segmented_image = centers[labels.flatten()]\n",
        "\n",
        "            # Reshape the segmented image to the original shape\n",
        "            segmented_image = segmented_image.reshape(image_rgb.shape)\n",
        "\n",
        "            # Save the segmented image\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, cv2.cvtColor(segmented_image, cv2.COLOR_RGB2BGR))\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/Kmeans_Res'\n",
        "\n",
        "# Define the number of clusters (k)\n",
        "num_clusters = 3\n",
        "\n",
        "# Call the function to perform k-means segmentation\n",
        "k_means_segmentation(input_folder, output_folder, num_clusters)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "GgoGrcU4hNLM",
        "outputId": "73d3cb19-35d3-47d0-8e69-da7f7eb321aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0361.jpg\n",
            "Processed 0170.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f10dfca4437e>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Call the function to perform k-means segmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mk_means_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-f10dfca4437e>\u001b[0m in \u001b[0;36mk_means_segmentation\u001b[0;34m(input_folder, output_folder, num_clusters)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Define criteria and apply k-means algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_EPS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTERM_CRITERIA_MAX_ITER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpixels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKMEANS_RANDOM_CENTERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Convert the centers back to uint8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NSMAnEUphKsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "imtDATq1hKpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IQe4Xu-thKjl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Blob Detector"
      ],
      "metadata": {
        "id": "ozJs_9-rb8No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def blob_detection(input_folder, output_folder):\n",
        "    # Setup SimpleBlobDetector parameters\n",
        "    params = cv2.SimpleBlobDetector_Params()\n",
        "\n",
        "    # Change thresholds\n",
        "    params.minThreshold = 10\n",
        "    params.maxThreshold = 200\n",
        "\n",
        "    # Filter by Area.\n",
        "    params.filterByArea = True\n",
        "    params.minArea = 100\n",
        "\n",
        "    # Filter by Circularity\n",
        "    params.filterByCircularity = True\n",
        "    params.minCircularity = 0.8\n",
        "\n",
        "    # Filter by Convexity\n",
        "    params.filterByConvexity = True\n",
        "    params.minConvexity = 0.87\n",
        "\n",
        "    # Filter by Inertia\n",
        "    params.filterByInertia = True\n",
        "    params.minInertiaRatio = 0.01\n",
        "\n",
        "    # Create a detector with the parameters\n",
        "    detector = cv2.SimpleBlobDetector_create(params)\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Detect blobs\n",
        "            keypoints = detector.detect(image)\n",
        "\n",
        "            # Draw blobs on the image\n",
        "            image_with_keypoints = cv2.drawKeypoints(image, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "\n",
        "            # Save the image with detected blobs\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, image_with_keypoints)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/BD'\n",
        "\n",
        "# Call the function to perform blob detection\n",
        "blob_detection(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyMURES_gwB1",
        "outputId": "6b2b0d0a-6cd4-40ed-d0ef-df1bbd3ef317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0361.jpg\n",
            "Processed 0170.jpg\n",
            "Processed 0160.jpg\n",
            "Processed 1714.jpg\n",
            "Processed 0027.jpg\n",
            "Processed 0127.jpg\n",
            "Processed 1546.jpg\n",
            "Processed 0154.jpg\n",
            "Processed 0347.jpg\n",
            "Processed 0150.jpg\n",
            "Processed 0567.jpg\n",
            "Processed 0205.jpg\n",
            "Processed 0007.jpg\n",
            "Processed 0174.jpg\n",
            "Processed 0356.jpg\n",
            "Processed 0575.jpg\n",
            "Processed 0129.jpg\n",
            "Processed 0163.jpg\n",
            "Processed 0126.jpg\n",
            "Processed 1785.jpg\n",
            "Processed 0014.jpg\n",
            "Processed 1784.jpg\n",
            "Processed 1797.jpg\n",
            "Processed 1547.jpg\n",
            "Processed 0563.jpg\n",
            "Processed 1712.jpg\n",
            "Processed 0005.jpg\n",
            "Processed 0186.jpg\n",
            "Processed 0023.jpg\n",
            "Processed 0159.jpg\n",
            "Processed 0348.jpg\n",
            "Processed 1791.jpg\n",
            "Processed 1799.jpg\n",
            "Processed 0562.jpg\n",
            "Processed 0016.jpg\n",
            "Processed 0364.jpg\n",
            "Processed 0009.jpg\n",
            "Processed 0146.jpg\n",
            "Processed 1793.jpg\n",
            "Processed 0354.jpg\n",
            "Processed 0569.jpg\n",
            "Processed 0204.jpg\n",
            "Processed 1710.jpg\n",
            "Processed 0351.jpg\n",
            "Processed 0156.jpg\n",
            "Processed 0171.jpg\n",
            "Processed 0006.jpg\n",
            "Processed 0564.jpg\n",
            "Processed 0151.jpg\n",
            "Processed 0191.jpg\n",
            "Processed 0585.jpg\n",
            "Processed 1798.jpg\n",
            "Processed 0359.jpg\n",
            "Processed 0178.jpg\n",
            "Processed 0193.jpg\n",
            "Processed 0010.jpg\n",
            "Processed 0197.jpg\n",
            "Processed 0346.jpg\n",
            "Processed 0162.jpg\n",
            "Processed 0157.jpg\n",
            "Processed 1539.jpg\n",
            "Processed 0565.jpg\n",
            "Processed 0580.jpg\n",
            "Processed 0026.jpg\n",
            "Processed 0573.jpg\n",
            "Processed 0180.jpg\n",
            "Processed 0004.jpg\n",
            "Processed 0571.jpg\n",
            "Processed 1544.jpg\n",
            "Processed 0085.jpg\n",
            "Processed 0201.jpg\n",
            "Processed 0188.jpg\n",
            "Processed 0579.jpg\n",
            "Processed 0177.jpg\n",
            "Processed 0582.jpg\n",
            "Processed 1545.jpg\n",
            "Processed 0190.jpg\n",
            "Processed 0022.jpg\n",
            "Processed 1715.jpg\n",
            "Processed 0200.jpg\n",
            "Processed 0572.jpg\n",
            "Processed 1792.jpg\n",
            "Processed 0196.jpg\n",
            "Processed 0173.jpg\n",
            "Processed 0189.jpg\n",
            "Processed 0013.jpg\n",
            "Processed 0020.jpg\n",
            "Processed 1801.jpg\n",
            "Processed 0578.jpg\n",
            "Processed 0153.jpg\n",
            "Processed 0166.jpg\n",
            "Processed 0131.jpg\n",
            "Processed 0187.jpg\n",
            "Processed 0577.jpg\n",
            "Processed 1796.jpg\n",
            "Processed 0021.jpg\n",
            "Processed 1709.jpg\n",
            "Processed 1790.jpg\n",
            "Processed 0182.jpg\n",
            "Processed 1549.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DOG"
      ],
      "metadata": {
        "id": "nrvCG_loduGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def difference_of_gaussians(input_folder, output_folder, ksize_large=(9, 9), sigma_large=3.0, ksize_small=(5, 5), sigma_small=1.0):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Apply Gaussian blur with a large kernel\n",
        "            large_blur = cv2.GaussianBlur(image, ksize_large, sigma_large)\n",
        "\n",
        "            # Apply Gaussian blur with a small kernel\n",
        "            small_blur = cv2.GaussianBlur(image, ksize_small, sigma_small)\n",
        "\n",
        "            # Compute the difference of Gaussians\n",
        "            dog = large_blur - small_blur\n",
        "\n",
        "            # Save the filtered image\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, dog)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/DOG'\n",
        "\n",
        "# Call the function to apply Difference of Gaussians\n",
        "difference_of_gaussians(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "gd8Io0aRdwbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Increase Brightness"
      ],
      "metadata": {
        "id": "9rEOvuuvLbiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import cv2\n",
        "\n",
        "def increase_contrast_brightness(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Increase contrast and brightness\n",
        "            alpha = 1.5  # Contrast control (1.0-3.0)\n",
        "            beta = 50  # Brightness control (0-100)\n",
        "            adjusted_image = cv2.convertScaleAbs(image, alpha=alpha, beta=beta)\n",
        "\n",
        "            # Save the adjusted image\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, adjusted_image)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/LOG'\n",
        "output_folder = '/content/drive/MyDrive/CB21'\n",
        "\n",
        "# Call the function to increase contrast and brightness\n",
        "increase_contrast_brightness(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtt1HBf2KvfS",
        "outputId": "f0529fd7-1042-437d-9620-5b9003de8ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0361.jpg\n",
            "Processed 0170.jpg\n",
            "Processed 0160.jpg\n",
            "Processed 1714.jpg\n",
            "Processed 0027.jpg\n",
            "Processed 0127.jpg\n",
            "Processed 1546.jpg\n",
            "Processed 0154.jpg\n",
            "Processed 0347.jpg\n",
            "Processed 0150.jpg\n",
            "Processed 0567.jpg\n",
            "Processed 0205.jpg\n",
            "Processed 0007.jpg\n",
            "Processed 0174.jpg\n",
            "Processed 0356.jpg\n",
            "Processed 0575.jpg\n",
            "Processed 0129.jpg\n",
            "Processed 0163.jpg\n",
            "Processed 0126.jpg\n",
            "Processed 1785.jpg\n",
            "Processed 0014.jpg\n",
            "Processed 1784.jpg\n",
            "Processed 1797.jpg\n",
            "Processed 1547.jpg\n",
            "Processed 0563.jpg\n",
            "Processed 1712.jpg\n",
            "Processed 0005.jpg\n",
            "Processed 0186.jpg\n",
            "Processed 0023.jpg\n",
            "Processed 0159.jpg\n",
            "Processed 0348.jpg\n",
            "Processed 1791.jpg\n",
            "Processed 1799.jpg\n",
            "Processed 0562.jpg\n",
            "Processed 0016.jpg\n",
            "Processed 0364.jpg\n",
            "Processed 0009.jpg\n",
            "Processed 0146.jpg\n",
            "Processed 1793.jpg\n",
            "Processed 0354.jpg\n",
            "Processed 0569.jpg\n",
            "Processed 0204.jpg\n",
            "Processed 1710.jpg\n",
            "Processed 0351.jpg\n",
            "Processed 0156.jpg\n",
            "Processed 0171.jpg\n",
            "Processed 0006.jpg\n",
            "Processed 0564.jpg\n",
            "Processed 0151.jpg\n",
            "Processed 0191.jpg\n",
            "Processed 0585.jpg\n",
            "Processed 1798.jpg\n",
            "Processed 0359.jpg\n",
            "Processed 0178.jpg\n",
            "Processed 0193.jpg\n",
            "Processed 0010.jpg\n",
            "Processed 0197.jpg\n",
            "Processed 0346.jpg\n",
            "Processed 0162.jpg\n",
            "Processed 0157.jpg\n",
            "Processed 1539.jpg\n",
            "Processed 0565.jpg\n",
            "Processed 0580.jpg\n",
            "Processed 0026.jpg\n",
            "Processed 0573.jpg\n",
            "Processed 0180.jpg\n",
            "Processed 0004.jpg\n",
            "Processed 0571.jpg\n",
            "Processed 1544.jpg\n",
            "Processed 0085.jpg\n",
            "Processed 0201.jpg\n",
            "Processed 0188.jpg\n",
            "Processed 0579.jpg\n",
            "Processed 0177.jpg\n",
            "Processed 0582.jpg\n",
            "Processed 1545.jpg\n",
            "Processed 0190.jpg\n",
            "Processed 0022.jpg\n",
            "Processed 1715.jpg\n",
            "Processed 0200.jpg\n",
            "Processed 0572.jpg\n",
            "Processed 1792.jpg\n",
            "Processed 0196.jpg\n",
            "Processed 0173.jpg\n",
            "Processed 0189.jpg\n",
            "Processed 0013.jpg\n",
            "Processed 0020.jpg\n",
            "Processed 1801.jpg\n",
            "Processed 0578.jpg\n",
            "Processed 0153.jpg\n",
            "Processed 0166.jpg\n",
            "Processed 0131.jpg\n",
            "Processed 0187.jpg\n",
            "Processed 0577.jpg\n",
            "Processed 1796.jpg\n",
            "Processed 0021.jpg\n",
            "Processed 1709.jpg\n",
            "Processed 1790.jpg\n",
            "Processed 0182.jpg\n",
            "Processed 1549.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LOG"
      ],
      "metadata": {
        "id": "7Lv5bTQ2ds8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Since the intensity is logarithmic in nature, human eyes' convention does not applyto very high or low gamma values as computer only uses pixel intensities"
      ],
      "metadata": {
        "id": "RH4-YOQagPIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def laplacian_of_gaussian(input_folder, output_folder, kernel_size=(5, 5), sigma=1.0):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Apply Gaussian blur\n",
        "            blurred = cv2.GaussianBlur(image, kernel_size, sigma)\n",
        "\n",
        "            # Apply Laplacian filter\n",
        "            laplacian = cv2.Laplacian(blurred, cv2.CV_64F)\n",
        "\n",
        "            # Convert Laplacian to uint8 image\n",
        "            laplacian = np.uint8(np.absolute(laplacian))\n",
        "\n",
        "            # Save the filtered image\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, laplacian)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/LOG'\n",
        "\n",
        "# Call the function to apply Laplacian of Gaussian\n",
        "laplacian_of_gaussian(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "jo-qofaXdw1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gabor Filter"
      ],
      "metadata": {
        "id": "sJo9lo37cv3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def gabor_filter(input_folder, output_folder, ksize=(21, 21), sigma=5.0, theta=np.pi/4, lambd=10.0, gamma=0.5):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Apply Gabor filter\n",
        "            gabor_kernel = cv2.getGaborKernel(ksize, sigma, theta, lambd, gamma)\n",
        "            filtered_image = cv2.filter2D(image, cv2.CV_8UC3, gabor_kernel)\n",
        "\n",
        "            # Save the filtered image\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, filtered_image)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/Gabor'\n",
        "\n",
        "# Call the function to apply Gabor filter\n",
        "gabor_filter(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "H2QI0lljcyHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LBP"
      ],
      "metadata": {
        "id": "vymgJYrWcs8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###There's no problem here, only taking a lot of time so stopped execution"
      ],
      "metadata": {
        "id": "2cbUXDyOfc1L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def local_binary_patterns(input_folder, output_folder, radius=1, neighbors=8):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Apply LBP\n",
        "            lbp = np.zeros_like(image)\n",
        "            for i in range(radius, image.shape[0] - radius):\n",
        "                for j in range(radius, image.shape[1] - radius):\n",
        "                    center = image[i, j]\n",
        "                    code = 0\n",
        "                    for k in range(neighbors):\n",
        "                        x = i + int(radius * np.cos(2 * np.pi * k / neighbors))\n",
        "                        y = j - int(radius * np.sin(2 * np.pi * k / neighbors))\n",
        "                        if image[x, y] >= center:\n",
        "                            code |= 1 << (neighbors - 1 - k)\n",
        "                    lbp[i, j] = code\n",
        "\n",
        "            # Save the LBP image\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, lbp)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/LBP'\n",
        "\n",
        "# Call the function to apply Local Binary Patterns\n",
        "local_binary_patterns(input_folder, output_folder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Kl9CNNAkcug2",
        "outputId": "fd142cbd-8e9c-42fc-ddfc-3a0aa39f1864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0361.jpg\n",
            "Processed 0170.jpg\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-4d679eb96fea>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Call the function to apply Local Binary Patterns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mlocal_binary_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-4d679eb96fea>\u001b[0m in \u001b[0;36mlocal_binary_patterns\u001b[0;34m(input_folder, output_folder, radius, neighbors)\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mcenter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CCA"
      ],
      "metadata": {
        "id": "H1RC_f_fcI7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def connected_component_analysis(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "            # Convert the image to binary\n",
        "            _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "            # Perform connected component analysis\n",
        "            num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary_image, connectivity=8)\n",
        "\n",
        "            # Filter out small components (optional)\n",
        "            min_area = 50  # Adjust this threshold according to your needs\n",
        "            filtered_labels = [label for label, stat in enumerate(stats) if stat[4] >= min_area]\n",
        "\n",
        "            # Create a mask to visualize the detected components\n",
        "            component_mask = np.zeros_like(binary_image)\n",
        "            for label in filtered_labels:\n",
        "                component_mask[labels == label] = 255\n",
        "\n",
        "            # Save the resulting mask\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, component_mask)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/CCA'\n",
        "\n",
        "# Call the function to perform connected component analysis\n",
        "connected_component_analysis(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "2c8wL55NcKpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FPN"
      ],
      "metadata": {
        "id": "SM88EYZta4w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def detect_objects_with_fpn(input_folder, output_folder):\n",
        "    # Load the pre-trained model\n",
        "    model_path = 'path/to/your/model.pb'\n",
        "    config_path = 'path/to/your/config.pbtxt'\n",
        "    net = cv2.dnn.readNet(model_path, config_path)\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Construct a blob from the image\n",
        "            blob = cv2.dnn.blobFromImage(image, swapRB=True, crop=False)\n",
        "\n",
        "            # Set the blob as input to the network\n",
        "            net.setInput(blob)\n",
        "\n",
        "            # Forward pass through the network to perform object detection\n",
        "            detections = net.forward()\n",
        "\n",
        "            # Draw bounding boxes on the original image for detected objects\n",
        "            for detection in detections[0, 0]:\n",
        "                confidence = detection[2]\n",
        "                if confidence > 0.5:  # You can adjust the confidence threshold as needed\n",
        "                    x1, y1, x2, y2 = int(detection[3] * image.shape[1]), int(detection[4] * image.shape[0]), int(detection[5] * image.shape[1]), int(detection[6] * image.shape[0])\n",
        "                    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "            # Save the image with bounding boxes drawn\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, image)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/FPN'\n",
        "\n",
        "# Call the function to detect objects using FPN\n",
        "detect_objects_with_fpn(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "yHDTZIF7a7ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SIFT"
      ],
      "metadata": {
        "id": "jjgD47-oa3aS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def extract_sift_features(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Iterate over each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "            # Read the image\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "\n",
        "            # Convert image to grayscale\n",
        "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Initialize SIFT detector\n",
        "            sift = cv2.SIFT_create()\n",
        "\n",
        "            # Detect keypoints and descriptors\n",
        "            keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
        "\n",
        "            # Draw keypoints on the original image\n",
        "            image_with_keypoints = cv2.drawKeypoints(image, keypoints, None)\n",
        "\n",
        "            # Save the image with keypoints overlaid\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            cv2.imwrite(output_path, image_with_keypoints)\n",
        "            print(f\"Processed {filename}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "output_folder = '/content/drive/MyDrive/SIFT_SURF'\n",
        "\n",
        "# Call the function to extract SIFT features\n",
        "extract_sift_features(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrMDltxBZlRW",
        "outputId": "9591e5cc-72b6-4f04-8d17-6fd384b7fc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0361.jpg\n",
            "Processed 0170.jpg\n",
            "Processed 0160.jpg\n",
            "Processed 1714.jpg\n",
            "Processed 0027.jpg\n",
            "Processed 0127.jpg\n",
            "Processed 1546.jpg\n",
            "Processed 0154.jpg\n",
            "Processed 0347.jpg\n",
            "Processed 0150.jpg\n",
            "Processed 0567.jpg\n",
            "Processed 0205.jpg\n",
            "Processed 0007.jpg\n",
            "Processed 0174.jpg\n",
            "Processed 0356.jpg\n",
            "Processed 0575.jpg\n",
            "Processed 0129.jpg\n",
            "Processed 0163.jpg\n",
            "Processed 0126.jpg\n",
            "Processed 1785.jpg\n",
            "Processed 0014.jpg\n",
            "Processed 1784.jpg\n",
            "Processed 1797.jpg\n",
            "Processed 1547.jpg\n",
            "Processed 0563.jpg\n",
            "Processed 1712.jpg\n",
            "Processed 0005.jpg\n",
            "Processed 0186.jpg\n",
            "Processed 0023.jpg\n",
            "Processed 0159.jpg\n",
            "Processed 0348.jpg\n",
            "Processed 1791.jpg\n",
            "Processed 1799.jpg\n",
            "Processed 0562.jpg\n",
            "Processed 0016.jpg\n",
            "Processed 0364.jpg\n",
            "Processed 0009.jpg\n",
            "Processed 0146.jpg\n",
            "Processed 1793.jpg\n",
            "Processed 0354.jpg\n",
            "Processed 0569.jpg\n",
            "Processed 0204.jpg\n",
            "Processed 1710.jpg\n",
            "Processed 0351.jpg\n",
            "Processed 0156.jpg\n",
            "Processed 0171.jpg\n",
            "Processed 0006.jpg\n",
            "Processed 0564.jpg\n",
            "Processed 0151.jpg\n",
            "Processed 0191.jpg\n",
            "Processed 0585.jpg\n",
            "Processed 1798.jpg\n",
            "Processed 0359.jpg\n",
            "Processed 0178.jpg\n",
            "Processed 0193.jpg\n",
            "Processed 0010.jpg\n",
            "Processed 0197.jpg\n",
            "Processed 0346.jpg\n",
            "Processed 0162.jpg\n",
            "Processed 0157.jpg\n",
            "Processed 1539.jpg\n",
            "Processed 0565.jpg\n",
            "Processed 0580.jpg\n",
            "Processed 0026.jpg\n",
            "Processed 0573.jpg\n",
            "Processed 0180.jpg\n",
            "Processed 0004.jpg\n",
            "Processed 0571.jpg\n",
            "Processed 1544.jpg\n",
            "Processed 0085.jpg\n",
            "Processed 0201.jpg\n",
            "Processed 0188.jpg\n",
            "Processed 0579.jpg\n",
            "Processed 0177.jpg\n",
            "Processed 0582.jpg\n",
            "Processed 1545.jpg\n",
            "Processed 0190.jpg\n",
            "Processed 0022.jpg\n",
            "Processed 1715.jpg\n",
            "Processed 0200.jpg\n",
            "Processed 0572.jpg\n",
            "Processed 1792.jpg\n",
            "Processed 0196.jpg\n",
            "Processed 0173.jpg\n",
            "Processed 0189.jpg\n",
            "Processed 0013.jpg\n",
            "Processed 0020.jpg\n",
            "Processed 1801.jpg\n",
            "Processed 0578.jpg\n",
            "Processed 0153.jpg\n",
            "Processed 0166.jpg\n",
            "Processed 0131.jpg\n",
            "Processed 0187.jpg\n",
            "Processed 0577.jpg\n",
            "Processed 1796.jpg\n",
            "Processed 0021.jpg\n",
            "Processed 1709.jpg\n",
            "Processed 1790.jpg\n",
            "Processed 0182.jpg\n",
            "Processed 1549.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rt6mH5PyZl2-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Gbe2EHytZl0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "D88ZFQm0ZlyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "I0ItvcFoZlrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EL54dXOZZlku"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def copy_first_100_images(input_folder, output_folder):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Get a list of all images in the input folder\n",
        "    images = [f for f in os.listdir(input_folder) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "\n",
        "    # Copy the first 100 images to the output folder\n",
        "    for i, image in enumerate(images[:100]):\n",
        "        src_path = os.path.join(input_folder, image)\n",
        "        dst_path = os.path.join(output_folder, image)\n",
        "        shutil.copyfile(src_path, dst_path)\n",
        "        print(f\"Copied {image}\")\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = '/content/drive/MyDrive/Dataset for unsupervised models'\n",
        "output_folder = '/content/drive/MyDrive/Dataset_2'\n",
        "\n",
        "# Call the function to copy the first 100 images\n",
        "copy_first_100_images(input_folder, output_folder)\n"
      ],
      "metadata": {
        "id": "640MEmh8ZpOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKJPl44EUc4c"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Set the path to the folder containing the test and train folders\n",
        "data_dir = 'path/to/folder'\n",
        "\n",
        "# Create ImageDataGenerator instances for training and testing\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training and testing data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    os.path.join(data_dir, 'test'),\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Create the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "model.evaluate(test_generator)\n",
        "\n",
        "# Save the model\n",
        "model.save('small_object_detection_model.h5')\n",
        "\n",
        "# Use the model for inference\n",
        "def classify_image(image_path):\n",
        "  # Load the image\n",
        "  img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
        "\n",
        "  # Convert the image to a numpy array\n",
        "  img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "\n",
        "  # Add a batch dimension to the image\n",
        "  img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "  # Classify the image\n",
        "  predictions = model.predict(img_array)\n",
        "\n",
        "  # Get the class with the highest probability\n",
        "  predicted_class = np.argmax(predictions[0])\n",
        "\n",
        "  # Get the class name\n",
        "  class_names = list(train_generator.class_indices.keys())\n",
        "  predicted_class_name = class_names[predicted_class]\n",
        "\n",
        "  # Return the predicted class name\n",
        "  return predicted_class_name\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7yX5S_1tZjez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: I'll give in the folder path which has images, create unsupervised object detection modelfor objcet detection\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Set the path to the folder containing the images\n",
        "folder_path = '/content/drive/MyDrive/Dataset_1'\n",
        "\n",
        "# Load the images from the folder\n",
        "images = []\n",
        "for filename in os.listdir(folder_path):\n",
        "  img = cv2.imread(os.path.join(folder_path, filename))\n",
        "  if img is not None:\n",
        "    images.append(img)\n",
        "\n",
        "# Convert the images to grayscale\n",
        "gray_images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
        "\n",
        "# Reshape the images to 2D arrays\n",
        "reshaped_images = [img.reshape(-1, img.shape[0] * img.shape[1]) for img in gray_images]\n",
        "\n",
        "# Concatenate the reshaped images into a single array\n",
        "all_pixels = np.concatenate(reshaped_images)\n",
        "\n",
        "# Perform K-Means clustering on the pixel data\n",
        "kmeans = KMeans(n_clusters=10)  # Adjust the number of clusters as needed\n",
        "kmeans.fit(all_pixels)\n",
        "\n",
        "# Get the cluster labels for each pixel\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Reshape the labels back to the shape of the original images\n",
        "segmented_images = [labels.reshape(img.shape[0], img.shape[1]) for img in images]\n",
        "\n",
        "# Save the segmented images\n",
        "for i, img in enumerate(segmented_images):\n",
        "  cv2.imwrite(os.path.join(folder_path, f'segmented_image_{i}.jpg'), img)\n"
      ],
      "metadata": {
        "id": "3srB-K7SVr44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def extract_jpg_files(input_folder, output_folder):\n",
        "\n",
        "\n",
        "  # Create the output folder if it doesn't exist\n",
        "  os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "  # Iterate over the files in the input folder\n",
        "  for file in os.listdir(input_folder):\n",
        "    # Check if the file is a JPG file\n",
        "    if file.endswith('.jpg'):\n",
        "      # Copy the file to the output folder\n",
        "      src_path = os.path.join(input_folder, file)\n",
        "      dst_path = os.path.join(output_folder, file)\n",
        "      shutil.copyfile(src_path, dst_path)\n",
        "\n",
        "\n",
        "# Get the input and output folder paths from the user\n",
        "input_folder = '/content/drive/MyDrive/Dataset for unsupervised models'\n",
        "output_folder = '/content/drive/MyDrive/Dataset_1'\n",
        "\n",
        "# Call the function to extract the JPG files\n",
        "extract_jpg_files(input_folder, output_folder)\n",
        "\n",
        "# Print a message to the user\n",
        "print('JPG files have been extracted to the specified output folder.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V4ltYDUWuzB",
        "outputId": "1c2e279d-c733-4c7a-e00a-7e240fad6f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JPG files have been extracted to the specified output folder.\n"
          ]
        }
      ]
    }
  ]
}